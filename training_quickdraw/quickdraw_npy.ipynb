{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: 'conda clean --source-cache' is deprecated.\n",
      "    Use 'conda build purge-all' to remove source cache files.\n",
      "Cache location: \n",
      "There are no tarballs to remove\n",
      "WARNING: /Users/babi/.conda/pkgs does not exist\n",
      "Cache location: \n",
      "There are no unused packages to remove\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda clean -tipsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/babi/Documents/GitHub/Quickdraw1/training_quickdraw\n",
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#import tensorflow_datasets as tfds\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib import image\n",
    "\n",
    "import random as rd\n",
    "import math as m\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import requests as req\n",
    "import csv\n",
    "import os\n",
    "print(os.getcwd())\n",
    "\n",
    "import copy\n",
    "\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_npy(categories,number_of_samples):\n",
    "\n",
    "    number_of_categories = len(categories)\n",
    "    data = np.array([], dtype=np.int64).reshape(0,784)\n",
    "    for i in range(number_of_categories):\n",
    "        filename = categories[i][0] + '.npy'\n",
    "        filename = filename.replace(\" \",\"%20\")\n",
    "        \n",
    "        url = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/'+filename\n",
    "        \n",
    "        r = req.get(url, allow_redirects=True)\n",
    "        #filename = os.path.basename(url)\n",
    "        #filename = filename.replace(\"%20\",\"\")\n",
    "        open(filename, 'wb').write(r.content)\n",
    "        \n",
    "        data = np.vstack([data,load_data(filename,number_of_samples)])\n",
    "        \n",
    "        os.remove(filename)\n",
    "        print(i+1,'/',number_of_categories,' ',filename.replace(\"%20\",\"\"))\n",
    "    return data\n",
    "\n",
    "def load_data(name,n):\n",
    "    filename = name\n",
    "    label = name\n",
    "    data = np.load(filename)\n",
    "    #data = np.ndarray.reshape(data,len(data),28,28)\n",
    "    return data[0:n,:]\n",
    "\n",
    "#randomize data and labels\n",
    "def shuff(data,label,seed):\n",
    "    \n",
    "    s = np.shape(data)\n",
    "    n = s[0]\n",
    "    \n",
    "    l = len(label)\n",
    "    label_new = np.zeros(l)\n",
    "    \n",
    "    if len(2*s)==2:\n",
    "        d = 1\n",
    "        m = 1\n",
    "        data_new = np.zeros((n,m))\n",
    "\n",
    "    elif len(2*s)==4:\n",
    "        d = 2\n",
    "        m = s[1]\n",
    "        data_new = np.zeros((n,m))\n",
    "    \n",
    "    \n",
    "    l1 = list(range(n))\n",
    "    l2 = list(range(n))\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(l1)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(l2)   \n",
    "    \n",
    "    for i in range(n):\n",
    "        data_new[i] = data[l1[i]]\n",
    "        label_new[i] = int(label[l2[i]])\n",
    "        \n",
    "    del data, label\n",
    "    return data_new, label_new\n",
    "\n",
    "def download_and_save(number_of_categories,number_of_samples):\n",
    "\n",
    "    x = [random.randint(0, 345) for p in range(0, number_of_categories)]\n",
    "\n",
    "    #load categories\n",
    "    categories = open(\"categories.txt\",'r')\n",
    "    reader = csv.reader(categories)\n",
    "    categories = [row for row in reader]\n",
    "    categories = [categories[row] for row in x]\n",
    "    \n",
    "    d = download_npy(categories,number_of_samples)\n",
    "    \n",
    "    #save Data\n",
    "    filename = 'dataset/data_{}_{}.csv'.format(number_of_categories,number_of_samples)\n",
    "    np.savetxt(filename, d, delimiter=',')\n",
    "    \n",
    "    #save Categories\n",
    "    filename = 'dataset/cat_{}_{}.csv'.format(number_of_categories,number_of_samples)\n",
    "    with open(filename, 'w') as f: \n",
    "        write = csv.writer(f) \n",
    "        write.writerows(categories)\n",
    "    return d, categories\n",
    "    \n",
    "def data_from_file(number_of_categories,number_of_samples):\n",
    "    \n",
    "    filename = 'dataset/data_{}_{}.csv'.format(number_of_categories,number_of_samples)\n",
    "    d = np.loadtxt(filename, delimiter=',')\n",
    "    filename = 'dataset/cat_{}_{}.csv'.format(number_of_categories,number_of_samples)\n",
    "    categories = open(filename,'r')\n",
    "    reader = csv.reader(categories)\n",
    "    categories = [row for row in reader]\n",
    "    \n",
    "    return d, categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories:  [['bucket'], ['bridge'], ['bracelet'], ['coffee cup'], ['streetlight']]\n",
      "(500, 784)   (500,)\n"
     ]
    }
   ],
   "source": [
    "number_of_categories = 5\n",
    "number_of_samples = 100\n",
    "\n",
    "##load data\n",
    "#d, cats = download_and_save(number_of_categories,number_of_samples)\n",
    "d, cats = data_from_file(number_of_categories,number_of_samples)\n",
    "\n",
    "cat_id = np.repeat(range(number_of_categories),number_of_samples)+1\n",
    "\n",
    "print('Categories: ', cats)\n",
    "print(np.shape(d),' ',np.shape(cat_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 28, 28)   (500,)\n"
     ]
    }
   ],
   "source": [
    "#Shuffle data\n",
    "data,cat_id = shuff(d,cat_id,13)\n",
    "\n",
    "#reshape data into 28x28\n",
    "data = np.reshape(data,(len(data),28,28))\n",
    "print(np.shape(data),' ',np.shape(cat_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.reshape(d,(len(d),28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Set:  Samples 400 / Labels 400\n",
      "Test-Set:  Samples 100 / Labels 100\n"
     ]
    }
   ],
   "source": [
    "#split data\n",
    "training = 0.8\n",
    "test = 1.-training\n",
    "\n",
    "x_train = data[0:m.floor(training*len(data))]/ 255.0\n",
    "y_train = cat_id[0:m.floor(training*len(cat_id))]\n",
    "\n",
    "x_test = data[m.ceil(training*len(data)):len(data)]/ 255.0\n",
    "y_test = cat_id[m.ceil(training*len(cat_id)):len(cat_id)]\n",
    "\n",
    "print('Train-Set: ','Samples',np.shape(x_train)[0],'/ Labels', np.shape(y_train)[0])\n",
    "print('Test-Set: ','Samples',np.shape(x_test)[0],'/ Labels', np.shape(y_test)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['coffee cup'] 219\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TEST Show\n",
    "i=rd.randint(1,len(x_train))\n",
    "plt.imshow(x_train[i])\n",
    "print(cats[int(cat_id[i]-1)],i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(number_of_categories),\n",
    "  tf.keras.layers.Softmax()\n",
    "])\n",
    "\n",
    "#define lossfunction\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# Compile: set optimizer, lossfunction, error metric\n",
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#train the model\n",
    "model.fit(x_train, y_train,batch_size = 50, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "len(x_train)/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 2.2234 - accuracy: 0.2110\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(x_test,  y_test, verbose=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2ad7fbba65de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = tf.keras.models.Sequential([\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_of_categories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(number_of_categories),\n",
    "  tf.keras.layers.Softmax()\n",
    "])\n",
    "\n",
    "#define lossfunction\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "\n",
    "# Compile and Fit in Batches\n",
    "x_train_len = len(x_train)\n",
    "y_train_len = len(y_train)\n",
    "#x_test_len = len(x_test)\n",
    "#y_test_len = len(y_test)\n",
    "\n",
    "batches = int(number_of_categories*number_of_samples/10)\n",
    "end = -1\n",
    "for i in range(batches):\n",
    "    \n",
    "    start = int(end+1)\n",
    "    end = int((i+1)*1/batches*x_train_len)\n",
    "    \n",
    "    x_train2 = x_train[start:end,:,:].copy()\n",
    "    y_train2 = y_train[start:end].copy()\n",
    "    #x_test = x_test[start:end,:]\n",
    "    #y_test = y_test[start:end]\n",
    "\n",
    "    # Run with new data\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=loss_fn,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    if i%10:\n",
    "        print('Batch No. ',i,'/',batches)\n",
    "    model.fit(x_train2, y_train2, epochs=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(number_of_categories),\n",
    "  tf.keras.layers.Softmax()\n",
    "])\n",
    "\n",
    "#define lossfunction\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# Run with new data\n",
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train2, y_train2, batch_size=5, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-959294c93992>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.evaluate(x_test,  y_test, verbose=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(number_of_categories*number_of_samples/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"qd.h5\"\n",
    "saved_model_dir = 'save/'+str(name)\n",
    "model.save(saved_model_dir)\n",
    "print('Model Saved to '+saved_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.saved_model.save(model,'save/')\n",
    "#converter = tf.lite.TFLiteConverter.from_keras_model_file(model)\n",
    "#Use this if 238 fails \n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "with open('model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('save/qd_0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('save/qd_0')\n",
    "new_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.evaluate(x_test,  y_test, verbose=2);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = new_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=2\n",
    "print(labels[np.argmax(predictions[i])])\n",
    "plt.figure()\n",
    "plt.imshow(x_test[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show PNG\n",
    "image = Image.open('dataset/airplane3.png')\n",
    "# convert image to numpy array\n",
    "data = asarray(image)\n",
    "data = abs(data-255.)/255.\n",
    "\n",
    "# summarize shape\n",
    "print(data.shape)\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert png to 28x28 array\n",
    "image = Image.open('dataset/airplane3.png')\n",
    "image_resize = image.resize((28,28))\n",
    "data_resize = asarray(image_resize)\n",
    "data_resize = abs(data_resize-255.)/255.\n",
    "data_resize = data_resize[:, :, 0]\n",
    "data_resize = np.expand_dims(data_resize, axis=0)\n",
    "\n",
    "#Predict png\n",
    "predictions = new_model.predict(data_resize)\n",
    "print(labels[np.argmax(predictions)])\n",
    "print(data_resize.shape)\n",
    "plt.imshow(image_resize)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
